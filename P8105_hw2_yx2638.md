P8105_hw2_yx2638
================
Yifei Xu
2022-09-28

``` r
library(tidyverse)
```

# Problem 1

``` r
# Read and clean the data
transit_df = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
        janitor::clean_names() %>%
        select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, 
               entrance_type,  ada) %>%
        mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE"),
               entry = as.logical(entry))


# names of important variables
variable_name = names(transit_df)

# size of the dataset 
row = nrow(transit_df)
col = ncol(transit_df)
```

The size of the dataset is 1868 rows \* 19 columns. The key variables
include line, station_name, station_latitude, station_longitude, route1,
route2, route3, route4, route5, route6, route7, route8, route9, route10,
route11, entry, vending, entrance_type, ada.

``` r
# Count the number of distinct stations
station_num = nrow(distinct(transit_df, line, station_name))

# Count the number of stations that are ADA compliant
ada_station_num = transit_df %>%
        filter(ada == "TRUE") %>%
        distinct(line, station_name) %>%
        nrow()

# Calculte the proportion of station entrances / exits without vending allow entrance ???distinct
no_vending_extrance_num = transit_df %>%
        filter(entry == "TRUE", vending == "NO") %>%
        nrow()

no_vending_num = transit_df %>%
        filter(vending == "NO") %>%
        nrow()

prop = scales::percent(no_vending_extrance_num / no_vending_num, 0.01)
```

There are 465 distinct stations and 84 stations are ADA compliant. The
proportion of station entrances / exits without vending allow entrance
is 37.70%.

``` r
# Reformat data so that route number and route name are distinct variables
transit_df_tidy = transit_df %>%
        mutate(
                route8 = as.character(route8),
                route9 = as.character(route9),
                route10 = as.character(route10),
                route11 = as.character(route11)
               ) %>%
        pivot_longer(
                route1:route11,
                names_to = "route_number",
                values_to = "route_name"
                )

# Count the number of distinct stations serve the A train
station_a_num = transit_df_tidy %>%
        filter(route_name == "A") %>%
        distinct(line, station_name) %>%
        nrow()

# Count the number of ADA compliant of the stations that serve the A train
station_a_ada_num = transit_df_tidy %>%
        filter(route_name == "A", ada == "TRUE") %>%
        distinct(line, station_name) %>%
        nrow()
```

60 distinct stations serve the A train, of which 17 are ADA compliant.

# Problem 2

``` r
# Read and clean the Mr. Trash Wheel sheet
mr_trash = readxl::read_excel("data/Trash Wheel Collection Data.xlsx", 
                              sheet = "Mr. Trash Wheel", 
                              range = cellranger::cell_cols("A:N")
                              )

mr_trash_tidy = mr_trash %>%
        janitor::clean_names() %>%
        drop_na(dumpster) %>%
        mutate(sports_balls = as.integer(round(sports_balls, digits = 0)))
```

``` r
# Read and clean the Professor Trash Wheel sheet
prof_trash = readxl::read_excel("data/Trash Wheel Collection Data.xlsx", 
                                sheet = "Professor Trash Wheel", 
                                range = cellranger::cell_cols("A:M") 
                                )

prof_trash_tidy = prof_trash %>%
        janitor::clean_names() %>%
        drop_na(dumpster) 
```

``` r
# Add a new variable in these two datasets
mr_trash_tidy_comb = mr_trash_tidy %>%
        mutate(wheel_name = "Mr. Trash Wheel")

prof_trash_tidy_comb = prof_trash_tidy %>%
        mutate(wheel_name = "Professor Trash Wheel",
               sports_balls = NA) %>%
        relocate(sports_balls, .before = "homes_powered") 

# Combine these two datasets
mr_prof_trash = rbind(mr_trash_tidy_comb, prof_trash_tidy_comb) %>%
        select(wheel_name, everything())
```

``` r
# Count the number of observations in the resulting dataset
mr_prof_nrow = nrow(mr_prof_trash)

# Give examples of key variables
mr_prof_var = names(mr_prof_trash)

# Calculate the total weight of trash collected by Professor Trash Wheel
prof_total_weight = mr_prof_trash %>%
        filter(wheel_name == "Professor Trash Wheel") %>%
        pull(weight_tons) %>%
        sum()

# Count the total number of sports balls collected by Mr. Trash Wheel in 2020
mr_total_balls = mr_prof_trash %>%
        filter(wheel_name == "Mr. Trash Wheel", year == "2020") %>%
        pull(sports_balls) %>%
        sum()
```

-   `Mr. Trash Wheel` dataset  
    The size of the tidy dataset is 547 rows \* 14 columns.  
    The key variables include dumpster, month, year, date, weight_tons,
    volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    glass_bottles, grocery_bags, chip_bags, sports_balls, homes_powered.

-   `Professor Trash Wheel` dataset  
    The size of the tidy dataset is 94 rows \* 13 columns.  
    The key variables include dumpster, month, year, date, weight_tons,
    volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    glass_bottles, grocery_bags, chip_bags, homes_powered.

-   Resulting(combining) dataset  
    There are 641 observations in the resulting dataset and the 15 key
    variables include wheel_name, dumpster, month, year, date,
    weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
    cigarette_butts, glass_bottles, grocery_bags, chip_bags,
    sports_balls, homes_powered.  
    The total weight of trash collected by Professor Trash Wheel was
    190.12 tons.  
    The total number of sports balls collected by Mr. Trash Wheel in
    2020 was 856.

# Problem 3

``` r
# Read and clean the data in pols-month.csv
pols = read_csv("data/pols-month.csv")

pols_tidy = pols %>%
        janitor::clean_names() %>%
        separate(mon, into = c("year", "month", "day")) %>%
        mutate(
                month = month.name[as.numeric(month)],
                year = as.numeric(year),
                president = case_when(prez_dem == 1 ~ "dem",
                               prez_gop == 1 ~ "gop",
                               prez_gop == 2 ~ "gop") 
                )%>%
         arrange(year, month) %>%
        select(-day, -prez_dem, -prez_gop)
```

``` r
# Read and clean the data in snp.csv
snp = read_csv("data/snp.csv")

snp_tidy = snp %>%
        janitor::clean_names() %>%
        separate(date, into = c("month", "day", "year"), sep ="/") %>%
        mutate(
                month = month.name[as.numeric(month)],
                year = as.numeric(year),
                year = ifelse(year < 23, year+2000, year+1900)
                ) %>%
        arrange(year, month) %>%
        select(year, month, close)
```

``` r
# Read and clean the data in unemployment.csv
unemployment = read_csv("data/unemployment.csv")

unemployment_tidy = unemployment %>%
        pivot_longer(
                Jan:Dec,
                names_to = "month",
                values_to = "unemployment_percent"
        ) %>%
        janitor::clean_names() %>% 
        mutate(
                month = match(month, month.abb),
                month = month.name[month]
                ) %>%
        arrange(year, month) 
```

``` r
# Join the datasets by merging snp into pols
pols_snp = left_join(pols_tidy, snp_tidy, by = c("year","month"))

# Join the datasets by merging unemployment into the result
pols_snp_employment = left_join(pols_snp, unemployment_tidy, by = c("year","month"))
```

``` r
# the dimension of the resulting dataset 
res_nrow = nrow(pols_snp_employment)
res_ncol = ncol(pols_snp_employment)

# range of years
res_year = pols_snp_employment %>%
        pull(year) %>% 
        range()

res_year_min = pols_snp_employment %>%
        pull(year) %>% 
        min()

res_year_max = pols_snp_employment %>%
        pull(year) %>% 
        max()

# names of key variables
res_var = names(pols_snp_employment)
```

-   `pols-month` dataset  
    The tidy `pols-month` dataset contains 822 observations and 9
    variables related to the number of national politicians who are
    democratic or republican from 1947 to 2015. Key variables include
    year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem,
    president.

-   `snp` dataset  
    The tidy `snp` dataset contains 787 observations and 3 variables
    related to Standard & Poor’s stock market index (S&P) with a year
    range from 1950 to 2015. Key variables include year, month, close.

-   `unemployment` dataset  
    The tidy `unemployment` dataset contains 816 observations and 3
    variables related to the number of national politicians who are
    democratic or republican from 1948 to 2015. Key variables include
    year, month, unemployment_percent.

-   Merged dataset `pols_snp_unemploymet`  
    The merged dataset `pols_snp` contains 822 observations and 11
    variables, with a range of years from 1947 to 2015. Key variables
    includes year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem,
    rep_dem, president, close, unemployment_percent, which represents
    year and month of the observation, the number of republican
    governors, the number of republican senators, the number of
    republican representatives, the number of democratic governors, the
    number of democratic senators, the number of democratic
    representatives on the associated date, the president’s political
    party, the closing values of the S&P stock index and percentage of
    unemployment on the associated date.By joining these three datasets,
    we can further analze how president’s political party affect
    economic outcomes such as stocks and unemployment.
